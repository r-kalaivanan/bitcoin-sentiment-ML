# main.py - Complete Bitcoin Sentiment ML Pipeline

"""
Bitcoin Sentiment ML - Complete Pipeline

This is the main entry point for the Bitcoin price prediction system.
It orchestrates the entire pipeline from data collection to prediction.

Usage:
    python main.py --mode [pipeline|train|predict]
    
    pipeline: Run complete pipeline (data collection ‚Üí training ‚Üí prediction)
    train: Train models only
    predict: Make prediction only
"""

import argparse
import os
import sys
from datetime import datetime

# Add scripts directory to path
sys.path.append('scripts')

from feature_engineering import FeatureEngineer
from sentiment_analysis import SentimentAnalyzer
from data_merger import DataMerger
from model_trainer import ModelTrainer
from predictor import BitcoinPredictor

def setup_directories():
    """Create necessary directories for the project."""
    directories = ['data', 'models', 'plots', 'predictions']
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
    print("‚úÖ Project directories ready")

def run_data_pipeline():
    """Run the complete data collection and preprocessing pipeline."""
    print("üöÄ Starting data pipeline...")
    
    # Step 1: Feature Engineering
    print("\n" + "="*50)
    print("STEP 1: FEATURE ENGINEERING")
    print("="*50)
    engineer = FeatureEngineer()
    price_data = engineer.generate_features()
    
    if price_data is None or len(price_data) == 0:
        print("‚ùå Feature engineering failed")
        return False
    
    # Step 2: Sentiment Analysis
    print("\n" + "="*50)
    print("STEP 2: SENTIMENT ANALYSIS")
    print("="*50)
    analyzer = SentimentAnalyzer()
    sentiment_data = analyzer.run_sentiment_pipeline(historical=True, scrape_recent=True)
    
    # Step 3: Data Merging
    print("\n" + "="*50)
    print("STEP 3: DATA MERGING")
    print("="*50)
    merger = DataMerger()
    merged_data = merger.run_merger_pipeline()
    
    if merged_data is None or len(merged_data) == 0:
        print("‚ùå Data pipeline failed")
        return False
    
    print("‚úÖ Data pipeline completed successfully")
    return True

def run_training_pipeline():
    """Run the model training pipeline."""
    print("\n" + "="*50)
    print("STEP 4: MODEL TRAINING")
    print("="*50)
    
    trainer = ModelTrainer()
    results = trainer.run_training_pipeline()
    
    if results is None:
        print("‚ùå Model training failed")
        return False
    
    print("‚úÖ Model training completed successfully")
    return True

def run_prediction():
    """Make a prediction using the trained model with real Twitter integration."""
    print("\n" + "="*50)
    print("STEP 5: PREDICTION")
    print("="*50)
    
    # Check if Twitter API is available for real-time sentiment
    try:
        from scripts.scrape import TwitterScraper
        scraper = TwitterScraper()
        
        if scraper.check_api_status():
            print("üê¶ Twitter API available - will use REAL sentiment data")
        else:
            print("‚ö†Ô∏è Twitter API not available - will use simulated sentiment data")
            print("üí° To use real data, set X_BEARER_TOKEN in .env file")
    except Exception as e:
        print(f"‚ö†Ô∏è Twitter API check failed: {e}")
        print("üîÑ Will use simulated sentiment data")
    
    predictor = BitcoinPredictor()
    result = predictor.run_prediction_pipeline()
    
    if result is None:
        print("‚ùå Prediction failed")
        return False
    
    print("‚úÖ Prediction completed successfully")
    return True

def main():
    """Main function to run the Bitcoin sentiment ML pipeline."""
    parser = argparse.ArgumentParser(description='Bitcoin Sentiment ML Pipeline')
    parser.add_argument('--mode', choices=['pipeline', 'train', 'predict'], 
                       default='pipeline', help='Mode to run')
    parser.add_argument('--skip-data', action='store_true', 
                       help='Skip data collection (use existing data)')
    
    args = parser.parse_args()
    
    print("ü™ô BITCOIN SENTIMENT ML PIPELINE")
    print("=" * 50)
    print(f"Mode: {args.mode}")
    print(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 50)
    
    # Setup project structure
    setup_directories()
    
    success = True
    
    if args.mode == 'pipeline':
        # Run complete pipeline
        if not args.skip_data:
            success = success and run_data_pipeline()
        
        if success:
            success = success and run_training_pipeline()
        
        if success:
            success = success and run_prediction()
    
    elif args.mode == 'train':
        # Run training only
        success = run_training_pipeline()
    
    elif args.mode == 'predict':
        # Run prediction only
        success = run_prediction()
    
    # Final status
    print("\n" + "="*50)
    if success:
        print("üéâ PIPELINE COMPLETED SUCCESSFULLY!")
        print("üìä Check the following for results:")
        print("   ‚Ä¢ data/ - Processed datasets")
        print("   ‚Ä¢ models/ - Trained models and results")
        print("   ‚Ä¢ plots/ - Performance visualizations")
        print("   ‚Ä¢ predictions/ - Latest predictions")
    else:
        print("‚ùå PIPELINE FAILED!")
        print("Please check the error messages above")
    print("="*50)
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
